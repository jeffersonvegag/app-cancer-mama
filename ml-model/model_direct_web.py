"""
Adaptaci√≥n DIRECTA de tu script que funciona
Solo cambiamos para recibir imagen desde web en lugar de ruta
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras import mixed_precision
from PIL import Image
import io
import tempfile

class DirectWebModel:
    def __init__(self):
        """Inicializar usando exactamente tu configuraci√≥n que funciona"""
        
        # Tu configuraci√≥n exacta
        mixed_precision.set_global_policy('mixed_float16')
        print("Pol√≠tica de precisi√≥n mixta establecida a 'mixed_float16'.")
        
        # Verificar GPU (tu c√≥digo exacto)
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                print(f"GPUs detectadas y configuradas: {gpus}")
            except RuntimeError as e:
                print(e)
        else:
            print("No se detectaron GPUs. La predicci√≥n se realizar√° en CPU.")
        
        # Rutas del modelo (tu configuraci√≥n)
        self.model_paths = [
            "/app/ml-model/breast_cancer_detection_model_transfer.h5",  # Docker
            "Z:/Trabajos/TrabajoTesis/dev_cruz_ml/app-cruz-ml/ml-model/breast_cancer_detection_model_transfer.h5",  # Local
            "../ml-model/breast_cancer_detection_model_transfer.h5",
            "./ml-model/breast_cancer_detection_model_transfer.h5"
        ]
        
        self.IMG_SIZE = 50  # Tu tama√±o exacto
        self.model = None
        self.model_loaded = False
        self.model_path = None
        
        # Cargar modelo usando tu m√©todo exacto
        self.load_model()
    
    def load_model(self):
        """Cargar modelo usando exactamente tu c√≥digo CON manejo de batch_shape"""
        
        for model_path in self.model_paths:
            if os.path.exists(model_path):
                try:
                    print(f"Intentando cargar modelo desde: {model_path}")
                    
                    # M√âTODO 1: Cargar directamente
                    try:
                        self.model = load_model(model_path)
                        self.model_path = model_path
                        self.model_loaded = True
                        print(f"‚úÖ Modelo cargado exitosamente desde: {model_path}")
                        self.model.summary()  # Tu l√≠nea exacta
                        return True
                    except Exception as e:
                        if 'batch_shape' in str(e):
                            print(f"‚ö†Ô∏è Error de batch_shape detectado, intentando con compile=False...")
                            # M√âTODO 2: Cargar sin compilar
                            try:
                                self.model = load_model(model_path, compile=False)
                                # Recompilar manualmente
                                self.model.compile(
                                    optimizer='adam',
                                    loss='binary_crossentropy',
                                    metrics=['accuracy']
                                )
                                self.model_path = model_path
                                self.model_loaded = True
                                print(f"‚úÖ Modelo cargado exitosamente (sin compilar) desde: {model_path}")
                                self.model.summary()
                                return True
                            except Exception as e2:
                                print(f"‚ùå Tambi√©n fall√≥ sin compilar: {e2}")
                                continue
                        else:
                            print(f"‚ùå Error cargando desde {model_path}: {e}")
                            continue
                            
                except Exception as e:
                    print(f"‚ùå Error general cargando desde {model_path}: {e}")
                    continue
        
        print("‚ùå No se pudo cargar el modelo desde ninguna ubicaci√≥n")
        return False
    
    def predict_single_image_bytes(self, image_bytes):
        """
        Adaptaci√≥n de tu funci√≥n predict_single_image para trabajar con bytes
        Mantiene EXACTAMENTE tu l√≥gica de predicci√≥n
        """
        
        if not self.model_loaded:
            print("‚ùå Modelo no cargado")
            return None, None
        
        try:
            # Convertir bytes a archivo temporal para usar tu c√≥digo exacto
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                tmp_file.write(image_bytes)
                temp_path = tmp_file.name
            
            try:
                # TU C√ìDIGO EXACTO desde aqu√≠
                
                # Cargar la imagen y redimensionarla (TU L√çNEA EXACTA)
                img = image.load_img(temp_path, target_size=(self.IMG_SIZE, self.IMG_SIZE))
                
                # Convertir la imagen a un array de NumPy (TU L√çNEA EXACTA)
                img_array = image.img_to_array(img)
                
                # Expandir las dimensiones (TU L√çNEA EXACTA)
                img_array = np.expand_dims(img_array, axis=0)
                
                # Normalizar los valores de los p√≠xeles (TU L√çNEA EXACTA)
                img_array /= 255.0

                # Realizar la predicci√≥n (TU L√çNEA EXACTA)
                prediction_proba = self.model.predict(img_array)[0][0]

                # Interpretar la predicci√≥n (TU C√ìDIGO EXACTO)
                if prediction_proba > 0.5:
                    prediction_label = "C√°ncer de Mama (IDC Positivo)"
                    has_cancer = True
                else:
                    prediction_label = "No C√°ncer (IDC Negativo)"
                    has_cancer = False

                print(f"üîç Predicci√≥n directa:")
                print(f"   - Probabilidad: {prediction_proba:.6f}")
                print(f"   - Clasificaci√≥n: {prediction_label}")

                return prediction_proba, prediction_label, has_cancer

            finally:
                # Limpiar archivo temporal
                os.unlink(temp_path)
                
        except Exception as e:
            print(f"‚ùå Error procesando imagen: {e}")
            return None, None, None
    
    def predict(self, image_input):
        """
        Funci√≥n para el sistema web que usa tu l√≥gica exacta
        """
        
        try:
            # Usar tu funci√≥n adaptada
            result = self.predict_single_image_bytes(image_input)
            
            if result[0] is not None:
                probability, label, has_cancer = result
                
                # Calcular confianza
                confidence = abs(probability - 0.5) * 2
                
                # Generar regi√≥n sospechosa simple si hay c√°ncer
                bbox = None
                if has_cancer:
                    bbox = {
                        'x': 15,
                        'y': 15,
                        'width': 20,
                        'height': 20
                    }
                
                # Formato para el backend
                return {
                    'probability': float(probability),
                    'has_cancer': bool(has_cancer),
                    'confidence': float(confidence),
                    'bbox': bbox,
                    'model_type': 'DirectWebModel_YourScript',
                    'model_path': self.model_path,
                    'image_size_used': self.IMG_SIZE
                }
            else:
                raise Exception("Error en predicci√≥n")
                
        except Exception as e:
            print(f"‚ùå Error en predict: {e}")
            raise e
    
    def get_model_info(self):
        """Informaci√≥n del modelo"""
        if not self.model_loaded:
            return {
                'loaded': False,
                'error': 'Modelo no cargado'
            }
        
        return {
            'loaded': True,
            'model_path': self.model_path,
            'image_size': self.IMG_SIZE,
            'model_type': 'Direct Web Model - Tu Script Exacto',
            'tf_version': tf.__version__
        }

# Exportar para el sistema
DirectRealModel = DirectWebModel
RealBreastCancerModel = DirectWebModel

def test_direct_web_model():
    """Probar el modelo web directo"""
    try:
        print("üß™ Probando modelo web directo...")
        
        model = DirectWebModel()
        
        if not model.model_loaded:
            print("‚ùå Modelo no cargado")
            return False
        
        # Crear imagen de prueba
        test_image = np.random.randint(0, 255, (50, 50, 3), dtype=np.uint8)
        pil_image = Image.fromarray(test_image)
        
        # Convertir a bytes
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        image_bytes = img_byte_arr.getvalue()
        
        result = model.predict(image_bytes)
        
        print(f"‚úÖ Resultado:")
        print(f"   - Probabilidad: {result['probability']:.6f}")
        print(f"   - Tiene c√°ncer: {result['has_cancer']}")
        print(f"   - Confianza: {result['confidence']:.4f}")
        print(f"   - Modelo: {result['model_type']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en prueba: {e}")
        return False

if __name__ == "__main__":
    print("üè• MODELO WEB DIRECTO - USANDO TU SCRIPT EXACTO")
    print("=" * 60)
    
    success = test_direct_web_model()
    
    if success:
        print("\\n‚úÖ Modelo web directo funcionando correctamente")
    else:
        print("\\n‚ùå Error en modelo web directo")
